library(dplyr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggplot2)
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
str(CapstoneDF)
summary(CapstoneDF)
dim(CapstoneDF)
CapstoneDF <- CapstoneDF  %>% mutate(Quarters = quarters.Date(Dates))
rm(list=ls())
WordCloudAnalysis <- function(dataset, use.sentences=TRUE){
#Remove "The" or "the"  from reviews, since the tm_map() function below doesn't do it.
dataset$Reviews <- gsub("[Tt]he", "", dataset$Reviews)
if(use.sentences==TRUE){
dataCorpus <- get_sentences(dataset$Reviews) %>% VectorSource %>% Corpus()
}
else {
#Create corpus from the full text data
dataCorpus <- dataset$Reviews %>% VectorSource() %>% Corpus()
}
#Remove punctuation and english stopwords from text data
dataCorpus <- dataCorpus %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower))
#Create term document matrix and convert to matrix class.
TDM <- TermDocumentMatrix(dataCorpus)
TDM_m <- TDM %>% as.matrix()
#Compute word frequencies from TDM.
wFreqs = sort(rowSums(TDM_m), decreasing=TRUE)
return(list("Corpus" = dataCorpus, "TDM"=TDM, "wordFreq"=wFreqs))
}
YearAnalysis <- function(df, auxdf, YearVal){
#Subset the data to obtain the desired year.
data <- df %>% subset(Year==YearVal)
print(paste("Here is a summary of the", YearVal, "data frame:"))
#Some summary output
cat("\n")
print(head(data[-1]))
cat("\n")
print(str(data))
cat("\n")
# Print mean value of ratings for that year
print(paste("The mean value of Ratings for", YearVal, "is: ", auxdf$MeanRating[auxdf$Year==YearVal]))
cat("\n")
readline(prompt="Press [Enter] to begin plotting.")
#Plot scatter plot of Ratings in the year, aggregated at the level of quarters
p1 <- ggplot(data,aes(x=YearQuarters, y=Ratings)) + stat_summary(fun.y=mean, geom="point")
print(p1)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot scatter plot of Ratings in the year, aggregated at the level of months.
p2 <- ggplot(data,aes(x=YearMonth, y=Ratings, col=YearQuarters)) + stat_summary(fun.y=mean, geom="point")
print(p2)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot histogram of Ratings, with Website information.
p3 <- ggplot(data,aes(ceiling(Ratings))) + geom_bar(aes(fill=Website))
print(p3)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot histogram of Rating, w Website info and faceted in quarters
p4 <- ggplot(data,aes(ceiling(Ratings))) + geom_bar(aes(fill=Website)) + facet_grid(.~YearQuarters)
print(p4)
readline(prompt="Press [Enter] to continue.")
#Create subsets of data for "good" and "bad" ratings.
dataBad <- data %>% subset(Ratings <= 3)
dataGood <- data %>% subset(Ratings > 3)
#Print ratios of bad and good ratings for this year.
print(paste("The percentage of 'bad' ratings in",YearVal,"is: ",auxdf$ratioBadRating[auxdf$Year==YearVal]))
print(paste("The percentage of 'good' ratings in",YearVal,"is: ", auxdf$ratioGoodRating[auxdf$Year==YearVal]))
cat("\n")
readline(prompt="Press [Enter] to begin text analysis.")
#Run text analysis on full, bad, and good data sets
data_wA <- WordCloudAnalysis(data)
dataBad_wA <- WordCloudAnalysis(dataBad)
dataGood_wA <- WordCloudAnalysis(dataGood)
#Print the most common words from the different data sets.
print("Most frequent words from all reviews: ")
print(head(data_wA$wordFreq))
cat("\n")
print("Most frequent words from 'bad' reviews: ")
print(head(dataBad_wA$wordFreq))
cat("\n")
print("Most frequent words from 'good' reviews: ")
print(head(dataGood_wA$wordFreq))
cat("\n")
readline(prompt="Press [Enter] to generate word cloud:")
# Plot word clouds
print("Plotting word cloud for 'bad' reviews." )
wordcloud(dataBad_wA$Corpus, max.words=200, random.order=F)
cat("\n")
readline(prompt="Press [Enter] to continue.")
print("Plotting word cloud for 'good' reviews." )
cat("\n")
wordcloud(dataGood_wA$Corpus, max.words=200, random.order=F)
}
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
library(readr)
library(dplyr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggplot2)
suppressMessages(library(dplyr))
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(readr))
YelpScrape <- function(BaseURL) {
ReviewCount <- 0 #Counter for the number of reviews. On the Yelp there are 20 per page
#Empty character vectors for the reviews and ratings
Reviews <- character(0)
Ratings <- character(0)
Dates <- character(0)
PrevRev <- character(0)
flag <- 1
#Now let's iterate over the different Yelp review pages and scrape the data.
while(flag==1){
#Yelp URL for the given review page
page_url <- paste(BaseURL,"?start=",as.character(ReviewCount),sep="")
#Scrape the reviews and ratings from the current URL
ReviewsNew <- read_html(page_url) %>% html_nodes(".review-content p") %>% html_text
RatingsNew <- read_html(page_url) %>% html_nodes(".rating-large") %>% html_attr("title")
DatesNew <- read_html(page_url) %>% html_nodes(".biz-rating-large .rating-qualifier") %>% html_text()
PrevRevNew <- read_html(page_url) %>% html_nodes(".biz-rating-large .rating-qualifier") %>% as.character()
print(paste("Scraping Yelp page",ceiling(ReviewCount/20)))
#Append new reviews/ratings to existing vectors
Reviews <- c(Reviews,ReviewsNew)
Ratings <- c(Ratings,RatingsNew)
Dates <- c(Dates, DatesNew)
PrevRev <- c(PrevRev,PrevRevNew)
#Increment the review counter to move to the next page in the following iteration
ReviewCount=ReviewCount +length(ReviewsNew)
#Loop ending condition
flag <- if(length(ReviewsNew)==0){0} else {1}
}
return(list("Reviews"=Reviews, "Ratings"=Ratings, "Dates"=Dates, "PrevRev"=PrevRev))
}
OpenTableScrape <- function(BaseURL) {
# Parameters
ReviewCount <- 1
Reviews <- character(0)
Ratings <- character(0)
Dates <- character(0)
flag <- 1
while(flag==1) {
#Get URL for current page
page_url <- paste(BaseURL,as.character(ReviewCount),sep="")
#Obtain ratings/reviews from page
ReviewsNew <- read_html(page_url) %>% html_nodes("#reviews-results .review-content") %>% html_text
RatingsNew <- read_html(page_url) %>% html_nodes("#reviews-results .filled") %>% html_attr("title")
DatesNew <- read_html(page_url) %>% html_nodes(".review-meta-separator+ .color-light") %>% html_text()
#Append ratings/reviews
Reviews <- c(Reviews,ReviewsNew)
Ratings <- c(Ratings,RatingsNew)
Dates <- c(Dates,DatesNew)
print(paste("Scraping OpenTable page",ReviewCount))
#Increment counter
ReviewCount <- ReviewCount+1
#This condition checks whether we have reached the end of the reviews
flag <- if(length(ReviewsNew)==0){0} else {1}
}
return(list("Reviews"=Reviews, "Ratings"=Ratings, "Dates"=Dates))
}
TripAdScrape <- function(LandingURL) {
#This gets the links to the review page, which are embedded in the review titles
ReviewTitleLink <- read_html(LandingURL) %>% html_nodes(".quote a") %>% html_attr("href")
#The base URL to the first review page is
BaseURL <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
#Set parameters for data scraping.
ReviewCount <- 1
Reviews <- character(0)
Ratings <- character(0)
Dates1 <- character(0)
Dates2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
Reviews <- c(Reviews, ReviewsNew)
Ratings <- c(Ratings, RatingsNew)
Dates1 <- c(Dates1, DatesNew1)
Dates2 <- c(Dates2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
return(list("Reviews"=Reviews,"Ratings"=Ratings, "Dates1"=Dates1,"Dates2"=Dates2))
}
ZomatoScrape <- function(BaseURL) {
#Set parameters for data scraping.
ReviewCount <- 1
Reviews <- character(0)
Ratings <- character(0)
Dates <- character(0)
flag <- 1
Reviews <- read_html(BaseURL) %>% html_nodes(".rev-text-expand , .rev-text") %>% html_text()
Ratings <- read_html(BaseURL) %>% html_nodes(".rev-text-expand div , .rev-text div") %>% html_attr("aria-label")
Dates <- read_html(BaseURL) %>% html_nodes("time") %>% html_attr("datetime")
return(list("Reviews"=Reviews,"Ratings"=Ratings, "Dates"=Dates))
}
BaseURL_Yelp <- "https://www.yelp.ca/biz/reds-midtown-tavern-toronto-2"
BaseURL_OpenTable <- "https://www.opentable.com/reds-midtown-tavern?covers=2&dateTime=2017-02-22+19%3A00%23reviews&page="
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
BaseURL_Zomato <- "https://www.zomato.com/toronto/reds-midtown-tavern-church-and-wellesley/reviews"
ZomatoData <- ZomatoScrape(BaseURL_Zomato)
YelpData <- YelpScrape(BaseURL_Yelp)
OpenTableData <- OpenTableScrape(BaseURL_OpenTable)
TripAdData <- TripAdScrape(LandingURL_TripAd)
library(rvest)
library(tidyr)
rm(list=ls())
library(rvest)
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(readr))
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(readr))
rm(list=ls())
WordCloudAnalysis <- function(dataset, use.sentences=TRUE){
#Remove "The" or "the"  from reviews, since the tm_map() function below doesn't do it.
dataset$Reviews <- gsub("[Tt]he", "", dataset$Reviews)
if(use.sentences==TRUE){
dataCorpus <- get_sentences(dataset$Reviews) %>% VectorSource %>% Corpus()
}
else {
#Create corpus from the full text data
dataCorpus <- dataset$Reviews %>% VectorSource() %>% Corpus()
}
#Remove punctuation and english stopwords from text data
dataCorpus <- dataCorpus %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower))
#Create term document matrix and convert to matrix class.
TDM <- TermDocumentMatrix(dataCorpus)
TDM_m <- TDM %>% as.matrix()
#Compute word frequencies from TDM.
wFreqs = sort(rowSums(TDM_m), decreasing=TRUE)
return(list("Corpus" = dataCorpus, "TDM"=TDM, "wordFreq"=wFreqs))
}
YearAnalysis <- function(df, auxdf, YearVal){
#Subset the data to obtain the desired year.
data <- df %>% subset(Year==YearVal)
print(paste("Here is a summary of the", YearVal, "data frame:"))
#Some summary output
cat("\n")
print(head(data[-1]))
cat("\n")
print(str(data))
cat("\n")
# Print mean value of ratings for that year
print(paste("The mean value of Ratings for", YearVal, "is: ", auxdf$MeanRating[auxdf$Year==YearVal]))
cat("\n")
readline(prompt="Press [Enter] to begin plotting.")
#Plot scatter plot of Ratings in the year, aggregated at the level of quarters
p1 <- ggplot(data,aes(x=YearQuarters, y=Ratings)) + stat_summary(fun.y=mean, geom="point")
print(p1)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot scatter plot of Ratings in the year, aggregated at the level of months.
p2 <- ggplot(data,aes(x=YearMonth, y=Ratings, col=YearQuarters)) + stat_summary(fun.y=mean, geom="point")
print(p2)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot histogram of Ratings, with Website information.
p3 <- ggplot(data,aes(ceiling(Ratings))) + geom_bar(aes(fill=Website))
print(p3)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot histogram of Rating, w Website info and faceted in quarters
p4 <- ggplot(data,aes(ceiling(Ratings))) + geom_bar(aes(fill=Website)) + facet_grid(.~YearQuarters)
print(p4)
readline(prompt="Press [Enter] to continue.")
#Create subsets of data for "good" and "bad" ratings.
dataBad <- data %>% subset(Ratings <= 3)
dataGood <- data %>% subset(Ratings > 3)
#Print ratios of bad and good ratings for this year.
print(paste("The percentage of 'bad' ratings in",YearVal,"is: ",auxdf$ratioBadRating[auxdf$Year==YearVal]))
print(paste("The percentage of 'good' ratings in",YearVal,"is: ", auxdf$ratioGoodRating[auxdf$Year==YearVal]))
cat("\n")
readline(prompt="Press [Enter] to begin text analysis.")
#Run text analysis on full, bad, and good data sets
data_wA <- WordCloudAnalysis(data)
dataBad_wA <- WordCloudAnalysis(dataBad)
dataGood_wA <- WordCloudAnalysis(dataGood)
#Print the most common words from the different data sets.
print("Most frequent words from all reviews: ")
print(head(data_wA$wordFreq))
cat("\n")
print("Most frequent words from 'bad' reviews: ")
print(head(dataBad_wA$wordFreq))
cat("\n")
print("Most frequent words from 'good' reviews: ")
print(head(dataGood_wA$wordFreq))
cat("\n")
readline(prompt="Press [Enter] to generate word cloud:")
# Plot word clouds
print("Plotting word cloud for 'bad' reviews." )
wordcloud(dataBad_wA$Corpus, max.words=200, random.order=F)
cat("\n")
readline(prompt="Press [Enter] to continue.")
print("Plotting word cloud for 'good' reviews." )
cat("\n")
wordcloud(dataGood_wA$Corpus, max.words=200, random.order=F)
}
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
library(readr)
library(dplyr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggplot2)
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
str(CapstoneDF)
str(CapstoneDF)
summary(CapstoneDF)
dim(CapstoneDF)
CapstoneDF <- CapstoneDF  %>% mutate(Quarters = quarters.Date(Dates))
CapstoneDF <- CapstoneDF %>% separate(Dates, c("Year","Month","Day"))
tempdf <- CapstoneDF %>% unite("YearMonth", Year, Month, sep="-")
CapstoneDF$YearMonth <- tempdf$YearMonth
tempdf <- CapstoneDF %>% unite("YearQuarters", Year, Quarters, sep="-")
CapstoneDF$YearQuarters <- tempdf$YearQuarters
CapstoneDF$Website <- factor(CapstoneDF$Website)
CapstoneDF$Quarters <- factor(CapstoneDF$Quarters)
head(CapstoneDF[-1])
wd=10.0
ht=10.0
mean(CapstoneDF$Ratings)
global_p1 <- ggplot(CapstoneDF, aes(x=Year, y=Ratings)) +
stat_summary(fun.y=mean, geom="point") +
coord_cartesian(ylim=c(2.5,4.5))
ggplot(CapstoneDF, aes(x=Website, y=ceiling(Ratings))) +
stat_summary(fun.y=mean, geom="point", size=10)
ggplot(CapstoneDF, aes(x=Website, y=ceiling(Ratings), col=Website)) +
stat_summary(fun.y=mean, geom="point", size=10)
yearVec <- sort(unique(as.numeric(CapstoneDF$Year)))
CapstoneDF_t <- CapstoneDF
CapstoneDF_t$Ratings <- ceiling(CapstoneDF_t$Ratings)
d1 <- CapstoneDF_t %>% group_by(Year,Ratings) %>% summarise(countRatings=n())
d2 <- CapstoneDF_t %>% group_by(Year) %>% summarise(countYear=n())
percentData <- left_join(d1,d2, by="Year")
percentData$Ratings <- ceiling(percentData$Ratings)
vec2 <- NULL
for(i in 1:length(yearVec)){
print(i)
vec <- percentData$Ratings %>% subset(percentData$Year == yearVec[i])
if(!(1 %in% vec)){
yearCount <- subset(percentData$countYear, percentData$Year==yearVec[i])[1]
vec2 <- data.frame(Year=as.character(yearVec[i]), Ratings=as.numeric(1), countRatings=as.integer(0), countYear=as.integer(yearCount))
print(vec2)
percentData <- (bind_rows(vec2, as.data.frame(percentData)))
}
}
percentData <- percentData %>% arrange(Ratings) %>%  mutate(percentRatings = countRatings/countYear)
percentData <- percentData %>% select(Year,Ratings,percentRatings, countYear) %>% arrange(Year,Ratings)
percentData$Ratings <- factor(percentData$Ratings)
ggplot(percentData, aes(x=Year, y=percentRatings, group=Ratings)) +
geom_line(aes(col=Ratings)) +
geom_point(aes(col=Ratings, size=countYear))
global_p10 <- ggplot(percentData, aes(x=Year, y=percentRatings, group=Ratings)) +
#geom_line(aes(col=Ratings)) +
geom_point(aes(col=Ratings,  size=countYear))
global_p10
global_p11 <- global_p10 +
geom_smooth(data=subset(percentData, percentData$Ratings==1), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.1, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==2), method="lm", se=T, formula=y~poly(x,1, raw=TRUE), linetype="dashed", size=0.5, alpha=0.1, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==3), method="lm", se=T, formula=y~poly(x,1, raw=TRUE), linetype="dashed", size=0.5, alpha=0.1, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==4), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.1, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==5), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.1, col="black")
global_p11
summary(lm(percentRatings ~ poly(as.numeric(Year),1), data=subset(percentData, percentData$Ratings==3)))
summary(lm(percentRatings ~ poly(as.numeric(Year),2), data=subset(percentData, percentData$Ratings==1)))
summary(lm(percentRatings ~ poly(as.numeric(Year),1), data=subset(percentData, percentData$Ratings==2)))
summary(lm(percentRatings ~ poly(as.numeric(Year),3), data=subset(percentData, percentData$Ratings==2)))
summary(lm(percentRatings ~ poly(as.numeric(Year),1), data=subset(percentData, percentData$Ratings==2)))
Capstone_wA <- WordCloudAnalysis(CapstoneDF)
??get_sentences
library(syuzhet)
rm(list=ls())
WordCloudAnalysis <- function(dataset, use.sentences=TRUE){
#Remove "The" or "the"  from reviews, since the tm_map() function below doesn't do it.
dataset$Reviews <- gsub("[Tt]he", "", dataset$Reviews)
if(use.sentences==TRUE){
dataCorpus <- get_sentences(dataset$Reviews) %>% VectorSource %>% Corpus()
}
else {
#Create corpus from the full text data
dataCorpus <- dataset$Reviews %>% VectorSource() %>% Corpus()
}
#Remove punctuation and english stopwords from text data
dataCorpus <- dataCorpus %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower))
#Create term document matrix and convert to matrix class.
TDM <- TermDocumentMatrix(dataCorpus)
TDM_m <- TDM %>% as.matrix()
#Compute word frequencies from TDM.
wFreqs = sort(rowSums(TDM_m), decreasing=TRUE)
return(list("Corpus" = dataCorpus, "TDM"=TDM, "wordFreq"=wFreqs))
}
YearAnalysis <- function(df, auxdf, YearVal){
#Subset the data to obtain the desired year.
data <- df %>% subset(Year==YearVal)
print(paste("Here is a summary of the", YearVal, "data frame:"))
#Some summary output
cat("\n")
print(head(data[-1]))
cat("\n")
print(str(data))
cat("\n")
# Print mean value of ratings for that year
print(paste("The mean value of Ratings for", YearVal, "is: ", auxdf$MeanRating[auxdf$Year==YearVal]))
cat("\n")
readline(prompt="Press [Enter] to begin plotting.")
#Plot scatter plot of Ratings in the year, aggregated at the level of quarters
p1 <- ggplot(data,aes(x=YearQuarters, y=Ratings)) + stat_summary(fun.y=mean, geom="point")
print(p1)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot scatter plot of Ratings in the year, aggregated at the level of months.
p2 <- ggplot(data,aes(x=YearMonth, y=Ratings, col=YearQuarters)) + stat_summary(fun.y=mean, geom="point")
print(p2)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot histogram of Ratings, with Website information.
p3 <- ggplot(data,aes(ceiling(Ratings))) + geom_bar(aes(fill=Website))
print(p3)
readline(prompt="Press [Enter] to generate the next plot.")
#Plot histogram of Rating, w Website info and faceted in quarters
p4 <- ggplot(data,aes(ceiling(Ratings))) + geom_bar(aes(fill=Website)) + facet_grid(.~YearQuarters)
print(p4)
readline(prompt="Press [Enter] to continue.")
#Create subsets of data for "good" and "bad" ratings.
dataBad <- data %>% subset(Ratings <= 3)
dataGood <- data %>% subset(Ratings > 3)
#Print ratios of bad and good ratings for this year.
print(paste("The percentage of 'bad' ratings in",YearVal,"is: ",auxdf$ratioBadRating[auxdf$Year==YearVal]))
print(paste("The percentage of 'good' ratings in",YearVal,"is: ", auxdf$ratioGoodRating[auxdf$Year==YearVal]))
cat("\n")
readline(prompt="Press [Enter] to begin text analysis.")
#Run text analysis on full, bad, and good data sets
data_wA <- WordCloudAnalysis(data)
dataBad_wA <- WordCloudAnalysis(dataBad)
dataGood_wA <- WordCloudAnalysis(dataGood)
#Print the most common words from the different data sets.
print("Most frequent words from all reviews: ")
print(head(data_wA$wordFreq))
cat("\n")
print("Most frequent words from 'bad' reviews: ")
print(head(dataBad_wA$wordFreq))
cat("\n")
print("Most frequent words from 'good' reviews: ")
print(head(dataGood_wA$wordFreq))
cat("\n")
readline(prompt="Press [Enter] to generate word cloud:")
# Plot word clouds
print("Plotting word cloud for 'bad' reviews." )
wordcloud(dataBad_wA$Corpus, max.words=200, random.order=F)
cat("\n")
readline(prompt="Press [Enter] to continue.")
print("Plotting word cloud for 'good' reviews." )
cat("\n")
wordcloud(dataGood_wA$Corpus, max.words=200, random.order=F)
}
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
library(readr)
library(dplyr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggplot2)
library(syuzhet)
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
str(CapstoneDF)
summary(CapstoneDF)
dim(CapstoneDF)
Capstone_wA <- WordCloudAnalysis(CapstoneDF)
names(Capstone_wA)
head(Capstone_wA$wordFreq, n=20)
findAssocs(Capstone_wA$TDM, "reds", 0.20)
findAssocs(Capstone_wA$TDM, "adelaide", 0.20)
findAssocs(Capstone_wA$TDM, "midtown", 0.20)
findAssocs(Capstone_wA$TDM, "food", .18)
length(CapstoneDF$Reviews[grepl("[Gg]ood",CapstoneDF$Reviews)]) #287 reviews
length(CapstoneDF$Reviews[grepl("[Gg]ood",CapstoneDF$Reviews)])/length(CapstoneDF$Reviews) #43%
mean(CapstoneDF$Ratings)
