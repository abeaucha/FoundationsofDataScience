DatesOpenTable[1:40]
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
ReviewTitleLink <- read_html(LandingURL_TripAd) %>% html_nodes(".quote a") %>% html_attr("href")
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
print(paste("Scraping Trip Advisor page",ReviewCount))
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("content")
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd
test <- read_html("https://www.tripadvisor.ca/ShowUserReviews-g155019-d5058760-r456753642-Reds_Midtown_Tavern-Toronto_Ontario.html#REVIEWS") %>% html_nodes(".relativeDate")
test
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
ReviewTitleLink <- read_html(LandingURL_TripAd) %>% html_nodes(".quote a") %>% html_attr("href")
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
print(DatesNew)
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
ReviewTitleLink <- read_html(LandingURL_TripAd) %>% html_nodes(".quote a") %>% html_attr("href")
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingeDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesNew1
DatesNew1
DatesTripAd11
DatesTripAd1
DatesTripAd2
DatesTripAd2
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
DatesTripAd2
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_node(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
quit("no")
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
RawDF <- read_csv("CapstoneRawData.csv")
str(RawDF)
summary(RawDF)
head(RawDF$Dates)
View(RawDF)
CleanDates <- grepl("^[0-9].*[0-9]$",RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=50)
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
RawDF <- read_csv("CapstoneRawData.csv")
str(RawDF)
summary(RawDF)
head(RawDF$Dates)
RawDF$Dates <- gsub("\n *","",RawDF$Dates)
CleanDates <- grepl("^[0-9].*[0-9]$",RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=50)
RawDF$Dates <- gsub("Updated review.*$","", RawDF$Dates)
RawDF$Dates <- gsub("Dined on ","",RawDF$Dates)
CleanDatesRegex <- "^[0-9].*[0-9]$|^([Jj]anuary|[Ff]ebruary|[Mm]arch|[Aa]pril|[Mm]ay|[Jj]une|[Jj]uly|[Aa]ugust|[Ss]eptember|[Oo]ctober|[Nn]ovember|[Dd]ecember).*[0-9]"
CleanDates <- grepl(CleanDatesRegex,RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=200)
CleanDatesRegex <- "(^[0-9].*[0-9]$)|^([Jj]anuary|[Ff]ebruary|[Mm]arch|[Aa]pril|[Mm]ay|[Jj]une|[Jj]uly|[Aa]ugust|[Ss]eptember|[Oo]ctober|[Nn]ovember|[Dd]ecember).*[0-9]"
CleanDates <- grepl(CleanDatesRegex,RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=200)
RawDF$Dates <- gsub("Reviewed ","",RawDF$Dates)
subset(RawDF$Dates, RawDF$Website=="Zomato")
head(subset(RawDF$Dates, RawDF$Website=="Zomato"))
head(subset(RawDF$Dates, RawDF$Website=="Yelp"))
head(subset(RawDF$Dates, RawDF$Website=="Yelp"))
YelpDateRegex <- grep("^[0-9]+/.*[0-9]$",RawDF$Dates)
RawDF$Dates[YelpDateRegex] <- RawDF$Dates[YelpDateRegex] %>% as.Date(format="%m/%d/%Y")
head(subset(RawDF$Dates, RawDF$Website=="OpenTable"))
OpenTableDateRegex <- grep("^([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",RawDF$Dates)
RawDF$Dates[OpenTableDateRegex] <- RawDF$Dates[OpenTableDateRegex] %>% as.Date(format="%B %d, %Y")
head(subset(RawDF$Dates, RawDF$Website=="OpenTable"))
summary(RawDF)
str(RawDF)
unique(RawDF$Website)
RScript DataGathering.R
head(subset(RawDF$Dates, RawDF$Website=="Trip Advisor"))
TripAdRegex <- grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$")
RawDF$Dates[TripAdRegex]
TripAdRegex <- grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",RawDF$Dates)
RawDF$Dates[TripAdRegex]
TripAdRegex <- grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",RawDF$Dates)
RawDF$Dates[TripAdRegex] <- RawDF$Dates[TripAdRegex] %>% as.Date(format="%d %B %Y")
head(subset(RawDF$Dates, RawDF$Website=="Trip Advisor"))
head(subset(RawDF$Dates, RawDF$Website=="Zomato"))
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
RawDF <- read_csv("CapstoneRawData.csv")
str(RawDF)
summary(RawDF)
head(RawDF$Dates)
unique(RawDF$Website)
RawDF$Dates <- gsub("\n *","",RawDF$Dates)
CleanDates <- grepl("^[0-9].*[0-9]$",RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=50)
RawDF$Dates <- gsub("Updated review.*$","", RawDF$Dates)
RawDF$Dates <- gsub("Dined on ","",RawDF$Dates)
CleanDatesRegex <- "(^[0-9].*[0-9]$)|^([Jj]anuary|[Ff]ebruary|[Mm]arch|[Aa]pril|[Mm]ay|[Jj]une|[Jj]uly|[Aa]ugust|[Ss]eptember|[Oo]ctober|[Nn]ovember|[Dd]ecember).*[0-9]"
CleanDates <- grepl(CleanDatesRegex,RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=200)
RawDF$Dates <- gsub("Reviewed ","",RawDF$Dates)
head(subset(RawDF$Dates, RawDF$Website=="Zomato"))
head(subset(RawDF$Dates, RawDF$Website=="Yelp"))
YelpDateRegex <- grep("^[0-9]+/.*[0-9]$",RawDF$Dates)
RawDF$Dates[YelpDateRegex] <- RawDF$Dates[YelpDateRegex] %>% as.Date(format="%m/%d/%Y")
head(subset(RawDF$Dates, RawDF$Website=="OpenTable"))
OpenTableDateRegex <- grep("^([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",RawDF$Dates)
RawDF$Dates[OpenTableDateRegex] <- RawDF$Dates[OpenTableDateRegex] %>% as.Date(format="%B %d, %Y")
head(subset(RawDF$Dates, RawDF$Website=="OpenTable"))
head(subset(RawDF$Dates, RawDF$Website=="Trip Advisor"))
TripAdRegex <- grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",RawDF$Dates)
RawDF$Dates[TripAdRegex] <- RawDF$Dates[TripAdRegex] %>% as.Date(format="%d %B %Y")
head(subset(RawDF$Dates, RawDF$Website=="Trip Advisor"))
head(subset(RawDF$Dates, RawDF$Website=="Zomato"))
subset(RawDF$Dates, RawDF$Website=="Zomato") %>% as.Date()
which(RawDF$Website == "Zomato")
RawDF$Dates[which(RawDF$Website == "Zomato")]
RawDF$Dates[which(RawDF$Website == "Zomato")] %>% as.Date()
RawDF$Dates[which(RawDF$Website == "Zomato")] <- RawDF$Dates[which(RawDF$Website == "Zomato")] %>% as.Date()
RawDF$Dates[which(RawDF$Website == "Zomato")] <- RawDF$Dates[which(RawDF$Website == "Zomato")] %>% as.Date()
head(subset(RawDF$Dates, RawDF$Website=="Zomato"))
class(RawDF$Dates) <- Date
class(RawDF$Dates) <- "Date"
str(RawDF$Dates)
str(RawDF)
head(subset(RawDF$Ratings, RawDF$Website=="Yelp"))
gsub("star rating","",RawDF$Ratings)
RawDF$Ratings <- gsub("star rating","",RawDF$Ratings)
head(subset(RawDF$Ratings, RawDF$Website=="Yelp"))
head(subset(RawDF$Ratings, RawDF$Website=="OpenTable"))
head(subset(RawDF$Ratings, RawDF$Website=="TripAdvisor"))
gsub("of [0-9] bubbles","",RawDF$Ratings)
RawDF$Ratings <- gsub("of [0-9] bubbles","",RawDF$Ratings)
head(subset(RawDF$Ratings, RawDF$Website=="TripAdvisor"))
head(subset(RawDF$Ratings, RawDF$Website=="Zomato"))
gsub("Rated","",RawDF$Ratings)
gsub("Rated ","",RawDF$Ratings)
RawDF$Ratings <- gsub("Rated ","",RawDF$Ratings)
head(subset(RawDF$Ratings, RawDF$Website=="Zomato"))
class(RawDF$Ratings) <- "numeric"
str(RawDF)
View(RawDF)
factor(RawDF$Website,order=FALSE,levels=c("Yelp","OpenTable","Zomato","TripAdvisor"))
RawDF$Website <- factor(RawDF$Website,order=FALSE,levels=c("Yelp","OpenTable","Zomato","TripAdvisor"))
str(RawDF)
head(subset(RawDF$Reviews, RawDF$Website=="Yelp"))
grep("\n",RawDF$Reviews)
head(RawDF$Reviews[grep("\n",RawDF$Reviews)])
gsub("\n","",RawDF$Reviews)
RawDF$Reviews <- gsub("\n","",RawDF$Reviews)
grep("\n",RawDF$Reviews)
write_csv(RawDF, "CapstoneCleanData.csv")
subset(RawDF$Reviews,Website="Zomato")
subset(RawDF$Reviews,RawDF$Website="Zomato")
subset(RawDF$Reviews,RawDF$Website=="Zomato")
grep(" +Rated +",RawDF$Reviews)
grep("\t+Rated +",RawDF$Reviews)
grep("\t+Rated",RawDF$Reviews)
grep("Rated",RawDF$Reviews)
grep(" Rated",RawDF$Reviews)
grep(" +Rated",RawDF$Reviews)
grep(" +Rated ",RawDF$Reviews)
grep(" Rated ",RawDF$Reviews)
grep(" Rated\t",RawDF$Reviews)
grep(" +Rated",RawDF$Reviews)
RawDF$Reviews[grep(" +Rated",RawDF$Reviews)]
RawDF$Reviews[grep(" +Rated",RawDF$Reviews)][1]
class(RawDF$Reviews[grep(" +Rated",RawDF$Reviews)][1])
RawDF$Reviews[grep(" +Rated",RawDF$Reviews)][1]
gsub(" +Rated","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
RawDF$Reviews <- gsub(" +Rated","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
RawDF$Reviews[grep(" +",RawDF$Reviews)]
RawDF$Reviews[grep("  +",RawDF$Reviews)]
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
RawDF <- read_csv("CapstoneRawData.csv")
str(RawDF)
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
RawDF <- read_csv("CapstoneRawData.csv")
str(RawDF)
summary(RawDF)
head(RawDF$Dates)
RawDF$Dates <- gsub("\n *","",RawDF$Dates)
CleanDates <- grepl("^[0-9].*[0-9]$",RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=50)
RawDF$Dates <- gsub("Updated review.*$","", RawDF$Dates)
RawDF$Dates <- gsub("Dined on ","",RawDF$Dates)
CleanDatesRegex <- "(^[0-9].*[0-9]$)|^([Jj]anuary|[Ff]ebruary|[Mm]arch|[Aa]pril|[Mm]ay|[Jj]une|[Jj]uly|[Aa]ugust|[Ss]eptember|[Oo]ctober|[Nn]ovember|[Dd]ecember).*[0-9]"
CleanDates <- grepl(CleanDatesRegex,RawDF$Dates)
UncleanInd <- which(CleanDates==FALSE)
UncleanDates <- RawDF$Dates[UncleanInd]
head(UncleanDates, n=200)
RawDF$Dates <- gsub("Reviewed ","",RawDF$Dates)
head(subset(RawDF$Dates, RawDF$Website=="Zomato"))
head(subset(RawDF$Dates, RawDF$Website=="Yelp"))
YelpDateRegex <- grep("^[0-9]+/.*[0-9]$",RawDF$Dates)
RawDF$Dates[YelpDateRegex] <- RawDF$Dates[YelpDateRegex] %>% as.Date(format="%m/%d/%Y")
head(subset(RawDF$Dates, RawDF$Website=="OpenTable"))
OpenTableDateRegex <- grep("^([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",RawDF$Dates)
RawDF$Dates[OpenTableDateRegex] <- RawDF$Dates[OpenTableDateRegex] %>% as.Date(format="%B %d, %Y")
head(subset(RawDF$Dates, RawDF$Website=="OpenTable"))
head(subset(RawDF$Dates, RawDF$Website=="Trip Advisor"))
TripAdRegex <- grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",RawDF$Dates)
RawDF$Dates[TripAdRegex] <- RawDF$Dates[TripAdRegex] %>% as.Date(format="%d %B %Y")
head(subset(RawDF$Dates, RawDF$Website=="Trip Advisor"))
head(subset(RawDF$Dates, RawDF$Website=="Zomato"))
RawDF$Dates[which(RawDF$Website == "Zomato")] <- RawDF$Dates[which(RawDF$Website == "Zomato")] %>% as.Date()
class(RawDF$Dates) <- "Date"
str(RawDF)
head(subset(RawDF$Ratings, RawDF$Website=="Yelp"))
RawDF$Ratings <- gsub("star rating","",RawDF$Ratings)
head(subset(RawDF$Ratings, RawDF$Website=="Yelp"))
head(subset(RawDF$Ratings, RawDF$Website=="OpenTable"))
head(subset(RawDF$Ratings, RawDF$Website=="TripAdvisor"))
RawDF$Ratings <- gsub("of [0-9] bubbles","",RawDF$Ratings)
head(subset(RawDF$Ratings, RawDF$Website=="TripAdvisor"))
head(subset(RawDF$Ratings, RawDF$Website=="Zomato"))
RawDF$Ratings <- gsub("Rated ","",RawDF$Ratings)
head(subset(RawDF$Ratings, RawDF$Website=="Zomato"))
class(RawDF$Ratings) <- "numeric"
RawDF$Website <- factor(RawDF$Website,order=FALSE,levels=c("Yelp","OpenTable","Zomato","TripAdvisor"))
str(RawDF)
RawDF$Reviews <- gsub("\n","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
RawDF$Reviews <- gsub(" +Rated +","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
RawDF$Reviews <- gsub(" +Rated  +","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
RawDF$Reviews <- gsub(" +Rated *","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
write_csv(RawDF, "CapstoneCleanData.csv")
RawDF$Reviews <- gsub(" +Rated.* +","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
RawDF$Reviews <- gsub(" +Rated *","",RawDF$Reviews)
subset(RawDF$Reviews,RawDF$Website=="Zomato")
setwd(CapstoneDir)
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
suppressMessages(library(rvest))
suppressMessages(library(dplyr))
suppressMessages(library(readr))
