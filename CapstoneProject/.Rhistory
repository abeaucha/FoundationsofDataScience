PrevRevYelp <- c(PrevRevYelp,PrevRevNew)
#Increment the review counter to move to the next page in the following iteration
ReviewCount=ReviewCount +length(ReviewsNew)
#Loop ending condition
flag <- if(length(ReviewsNew)==0){0} else {1}
}
head(DatesYelp)
tail(DatesYelp)
head(PrevRevYelp)
head(RatingsYelp)
PrevRevYelp[1:20]
PrevRevYelp[1:40]
rm(list=ls())
library(rvest)
library(dplyr)
library(tidyr)
BaseURL_Yelp <- "https://www.yelp.ca/biz/reds-midtown-tavern-toronto-2"
ReviewCount <- 0 #Counter for the number of reviews. On the Yelp there are 20 per page
ReviewsYelp <- character(0)
RatingsYelp <- character(0)
DatesYelp <- character(0)
PrevRevYelp <- character(0)
flag <- 1
while(flag==1){
#Yelp URL for the given review page
page_url <- paste(BaseURL_Yelp,"?start=",as.character(ReviewCount),sep="")
#Scrape the reviews and ratings from the current URL
ReviewsNew <- read_html(page_url) %>% html_nodes(".review-content p") %>% html_text
RatingsNew <- read_html(page_url) %>% html_nodes(".rating-large") %>% html_attr("title")
DatesNew <- read_html(page_url) %>% html_nodes(".biz-rating-large .rating-qualifier") %>% html_text()
PrevRevNew <- read_html(page_url) %>% html_nodes(".biz-rating-large .rating-qualifier") %>% as.character()
print(paste("Scraping Yelp page",ceiling(ReviewCount/20)))
#Append new reviews/ratings to existing vectors
ReviewsYelp <- c(ReviewsYelp,ReviewsNew)
RatingsYelp <- c(RatingsYelp,RatingsNew)
DatesYelp <- c(DatesYelp, DatesNew)
PrevRevYelp <- c(PrevRevYelp,PrevRevNew)
#Increment the review counter to move to the next page in the following iteration
ReviewCount=ReviewCount +length(ReviewsNew)
#Loop ending condition
flag <- if(length(ReviewsNew)==0){0} else {1}
}
PrevRevYelp[30:40]
PrevRevYelp[1:40]
BaseURL_OpenTable <- "https://www.opentable.com/reds-midtown-tavern?covers=2&dateTime=2017-02-22+19%3A00%23reviews&page="
ReviewCount <- 1
ReviewsOpenTable <- character(0)
RatingsOpenTable <- character(0)
DatesOpenTable <- character(0)
flag <- 1
while(flag==1) {
#Get URL for current page
page_url <- paste(BaseURL_OpenTable,as.character(ReviewCount),sep="")
#Obtain ratings/reviews from page
ReviewsNew <- read_html(page_url) %>% html_nodes("#reviews-results .review-content") %>% html_text
RatingsNew <- read_html(page_url) %>% html_nodes("#reviews-results .filled") %>% html_attr("title")
DatesOpenTableNew <- read_html(page_url) %>% html_nodes(".review-meta-separator+ .color-light") %>% html_text()
#Append ratings/reviews
ReviewsOpenTable <- c(ReviewsOpenTable,ReviewsNew)
RatingsOpenTable <- c(RatingsOpenTable,RatingsNew)
DatesOpenTable <- c(DatesOpenTable,DatesOpenTableNew)
print(paste("Scraping OpenTable page",ReviewCount))
#Increment counter
ReviewCount <- ReviewCount+1
#This condition checks whether we have reached the end of the reviews
flag <- if(length(ReviewsNew)==0){0} else {1}
}
DatesOpenTable[1:20]
Sys.time()
sys.date()
sys.Date()
?sys
Sys.Date()
DatesOpenTable[1:40]
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
ReviewTitleLink <- read_html(LandingURL_TripAd) %>% html_nodes(".quote a") %>% html_attr("href")
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
print(paste("Scraping Trip Advisor page",ReviewCount))
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("content")
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd
test <- read_html("https://www.tripadvisor.ca/ShowUserReviews-g155019-d5058760-r456753642-Reds_Midtown_Tavern-Toronto_Ontario.html#REVIEWS") %>% html_nodes(".relativeDate")
test
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
ReviewTitleLink <- read_html(LandingURL_TripAd) %>% html_nodes(".quote a") %>% html_attr("href")
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
print(DatesNew)
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
ReviewTitleLink <- read_html(LandingURL_TripAd) %>% html_nodes(".quote a") %>% html_attr("href")
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingeDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesNew1
DatesNew1
DatesTripAd11
DatesTripAd1
DatesTripAd2
DatesTripAd2
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
DatesTripAd2
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_node(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
quit("no")
suppressMessages(library(rvest))
YelpURL <- "https://www.yelp.ca/biz/reds-midtown-tavern-toronto-2"
YelpURL_data <-read_html(YelpURL)
print(YelpURL_data)
length(YelpURL_data)
YelpURL_data[2]
YelpReviews <- html_nodes(YelpURL_data)
YelpReviews <- html_nodes(YelpURL_data, ".review-content p")
YelpReviews
head(YelpReviews)
head(as.character(YelpReviews))
YelpReviews_char1 <- as.character(YelpReviews)
head(YelpReviews_char1)
head(YelpReviews_char1, n=2)
YelpReviews_char2 <- html_text(YelpReviews)
head(YelpReviews, n=2)
head(YelpReviews_char2, n=2)
head(YelpReviews)
html_attrs(YelpReviews)
html_attrs(YelpReviews, "lang")
html_attrs(YelpReviews, lang)
html_attrs(YelpReviews, "en")
?html_attrs
html_attr(YelpReviews, "en")
html_attr(YelpReviews, "lang")
html_attr(YelpReviews, "lang")
html_attrs(YelpReviews)
head(html_attrs(YelpReviews))
head(html_attr(YelpReviews, "lang"))
YelpRatings <- html_nodes(YelpURL_data, ".rating-large"")
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
YelpRatings
as.character(YelpRatings)[1]
html_attrs(YelpRatings)
YelpRatings <- html_nodes(YelpURL_data, ".rating-large img")
as.character(YelpRatings)[1]
```{r}
html_attrs(YelpRatings)
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
html_attrs(YelpRatings)
head(html_attrs(YelpRatings))
YelpRatings_clean <- html_attr(YelpRatings, "title")
head(YelpRatings_clean)
head(html_attrs(YelpReviews), n=3)
class(html_attrs(YelpReviews))
class(html_attr(YelpReviews, "lang"))
head(html_attrs(YelpRatings), n=3)
rm(list=ls())
suppressMessages(library(rvest))
suppressMessages(library(dplyr))
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(readr))
head(CapstoneDF$Dates, n=50)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"),n=20)
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
devtools::install_github("rstudio/rmarkdown")
library(readr)
library(dplyr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggplot2)
suppressMessages(library(syuzhet))
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
CapstoneDF <- suppressMessages(read_csv("./Data/CapstoneCleanData.csv"))
str(CapstoneDF)
summary(CapstoneDF)
glimpe(CapstoneDF)
glimpse(CapstoneDF)
str(CapstoneDF)
glimpse(CapstoneDF)
dim(CapstoneDF)
glimpse(CapstoneDF)
glimpse(CapstoneDF)
global_p1 <- ggplot(CapstoneDF, aes(x=Year, y=Ratings)) +
stat_summary(fun.y=mean, geom="point") +
coord_cartesian(ylim=c(2.5,4.5))
global_p1
CapstoneDF <- suppressMessages(read_csv("./Data/CapstoneCleanData.csv"))
glimpse(CapstoneDF)
CapstoneDF <- CapstoneDF  %>% mutate(Quarters = quarters.Date(Dates))
CapstoneDF <- CapstoneDF %>% separate(Dates, c("Year","Month","Day"))
tempdf <- CapstoneDF %>% unite("YearMonth", Year, Month, sep="-")
CapstoneDF$YearMonth <- tempdf$YearMonth
tempdf <- CapstoneDF %>% unite("YearQuarters", Year, Quarters, sep="-")
CapstoneDF$YearQuarters <- tempdf$YearQuarters
CapstoneDF$Website <- factor(CapstoneDF$Website)
CapstoneDF$Quarters <- factor(CapstoneDF$Quarters)
head(CapstoneDF[-1])
global_p1 <- ggplot(CapstoneDF, aes(x=Year, y=Ratings)) +
stat_summary(fun.y=mean, geom="point") +
coord_cartesian(ylim=c(2.5,4.5))
global_p1
global_p2 <- ggplot(CapstoneDF, aes(x=YearQuarters, y=Ratings)) +
stat_summary(fun.y=mean, geom="point") +
coord_cartesian(ylim=c(2.5,4.5))
global_p2
warnings()
global_p2 <- ggplot(CapstoneDF, aes(x=YearQuarters, y=Ratings)) +
stat_summary(fun.y=mean, geom="point") +
coord_cartesian(ylim=c(2.5,4.5))
global_p2
global_p3 <- ggplot(CapstoneDF, aes(x=YearMonth, y=Ratings, col=YearQuarters)) +
stat_summary(fun.y=mean, geom="point") +
coord_cartesian(ylim=c(2.5,4.5)) +
theme(axis.text.x =element_text(angle=90))
warnings()
global_p2 <- ggplot(CapstoneDF, aes(x=YearQuarters, y=Ratings)) +
stat_summary(fun.y=mean, geom="point") +
stat_summary(fun.y=sd, geom="pointrange") +
coord_cartesian(ylim=c(2.5,4.5)) +
theme(axis.text.x =element_text(angle=90))
install.packages("rticles",type="source")
??knitr
install.packages("knitr")
??opts_chunk
library(knitr)
opts_chunk$get("out.width")
opts_chunk$get("ehco)
opts_chunk$get("echo")
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(png)
install.packages("png")
install.packages("grid")
library(png)
library(grid)
img <- readPNG("./REDSYelpReviews.png")
grid.raster(img)
library(png)
library(grid)
img <- readPNG("./REDSYelpReviews.png")
grid.raster(img)
print("<p lang=\\ "en\\  ">")
print("<p lang=\"en\">")
"hello"+"world"
paste("hello","world")
paste("hello","world")
paste("hello",
"world)"
"world)")
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
library(rvest)
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(readr))
load("./Data/CapstoneRawData.RData")
t1 <- grepl("has-previous-review",YelpData$PrevRev) == FALSE
t2 <- !grepl("has-previous-review",YelpData$PrevRev)
head(t1)
head(t2)
t1 == t2
!which(t1==t2)
which(t1==t2)
which(t1!=t2)
?printr
install.packages("printr")
?str()
?head
?opts_chunk
?highlight
install.packages("highlight")
?highlight
?highlight
??highlight
library(highlight)
highlight_themes()
highlight_output_types()
devtools::install_github("rstudio/rmarkdown")
