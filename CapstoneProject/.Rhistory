#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
print(DatesNew)
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd <- c(DatesTripAd, DatesNew)
#Increment page count
ReviewCount <- ReviewCount+1
}
LandingURL_TripAd <- "https://www.tripadvisor.ca/Restaurant_Review-g155019-d5058760-Reviews-Reds_Midtown_Tavern-Toronto_Ontario.html"
ReviewTitleLink <- read_html(LandingURL_TripAd) %>% html_nodes(".quote a") %>% html_attr("href")
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title")
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingeDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesNew1
DatesNew1
DatesTripAd11
DatesTripAd1
DatesTripAd2
DatesTripAd2
BaseURL_TripAd <- paste("https://www.tripadvisor.ca",ReviewTitleLink[1],sep="")
ReviewCount <- 1
ReviewsTripAd <- character(0)
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
DatesTripAd2
RatingsTripAd <- character(0)
DatesTripAd1 <- character(0)
DatesTripAd2 <- character(0)
flag <- 1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_node(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
while(flag==1){
print(paste("Scraping Trip Advisor page",ReviewCount))
#For the first page, the URL we want to use is jsut the base URL. For subsequent
#iterations, we want to grab the hyperlink to the new page from the page links
#in the previous page. E.g. page 1 carries a link to page 2 in its HTML.
if(ReviewCount == 1){
page_url <- BaseURL_TripAd
} else {
#Grab the page numbers for the links
pagenum <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("data-page-number") %>% as.numeric()
#Grab the hyperlinks for the following pages
hyperlink <- read_html(page_url) %>% html_nodes(".pageNum") %>% html_attr("href") %>% as.character()
page_url <- paste("https://www.tripadvisor.ca",hyperlink[pagenum==ReviewCount],sep="")
}
#Read in reviews and ratings from current page
ReviewsNew <- read_html(page_url) %>% html_nodes("#REVIEWS p") %>% html_text()
RatingsNew <- read_html(page_url) %>% html_nodes("#REVIEWS .rating_s_fill") %>% html_attr("alt")
DatesNew1 <- read_html(page_url) %>% html_nodes(".relativeDate") %>% html_attr("title",default=NA_character_)
DatesNew2 <- read_html(page_url) %>% html_nodes(".ratingDate") %>% html_text()
#End loop condition
flag <- if(length(ReviewsNew)==0){0} else {1}
#Append new reviews/ratings
ReviewsTripAd <- c(ReviewsTripAd, ReviewsNew)
RatingsTripAd <- c(RatingsTripAd, RatingsNew)
DatesTripAd1 <- c(DatesTripAd1, DatesNew1)
DatesTripAd2 <- c(DatesTripAd2, DatesNew2)
#Increment page count
ReviewCount <- ReviewCount+1
}
DatesTripAd1
quit("no")
suppressMessages(library(rvest))
YelpURL <- "https://www.yelp.ca/biz/reds-midtown-tavern-toronto-2"
YelpURL_data <-read_html(YelpURL)
print(YelpURL_data)
length(YelpURL_data)
YelpURL_data[2]
YelpReviews <- html_nodes(YelpURL_data)
YelpReviews <- html_nodes(YelpURL_data, ".review-content p")
YelpReviews
head(YelpReviews)
head(as.character(YelpReviews))
YelpReviews_char1 <- as.character(YelpReviews)
head(YelpReviews_char1)
head(YelpReviews_char1, n=2)
YelpReviews_char2 <- html_text(YelpReviews)
head(YelpReviews, n=2)
head(YelpReviews_char2, n=2)
head(YelpReviews)
html_attrs(YelpReviews)
html_attrs(YelpReviews, "lang")
html_attrs(YelpReviews, lang)
html_attrs(YelpReviews, "en")
?html_attrs
html_attr(YelpReviews, "en")
html_attr(YelpReviews, "lang")
html_attr(YelpReviews, "lang")
html_attrs(YelpReviews)
head(html_attrs(YelpReviews))
head(html_attr(YelpReviews, "lang"))
YelpRatings <- html_nodes(YelpURL_data, ".rating-large"")
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
YelpRatings
as.character(YelpRatings)[1]
html_attrs(YelpRatings)
YelpRatings <- html_nodes(YelpURL_data, ".rating-large img")
as.character(YelpRatings)[1]
```{r}
html_attrs(YelpRatings)
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
html_attrs(YelpRatings)
head(html_attrs(YelpRatings))
YelpRatings_clean <- html_attr(YelpRatings, "title")
head(YelpRatings_clean)
head(html_attrs(YelpReviews), n=3)
class(html_attrs(YelpReviews))
class(html_attr(YelpReviews, "lang"))
head(html_attrs(YelpRatings), n=3)
rm(list=ls())
suppressMessages(library(rvest))
suppressMessages(library(dplyr))
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(readr))
head(CapstoneDF$Dates, n=50)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"),n=20)
?wordcloud
library(readr)
library(dplyr)
library(tm)
library(wordcloud)
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
test <- CapstoneDF$Reviews %>% VectorSource()
head(test)
test.corpus <- test %>% Corpus()
print(test.corpus)
inspect(test.corpus[[1]])
meta(test.corpus[[1]])
lapply(test.corpus[1:5],as.character)
test1 <- tm_map(test.corpus, removePunctuation)
inspect(test1[1])
test2 <- tm_map(test.corpus, removeWords, stopwords("english"))
inspect(test2[1])
inspect(test1[1])
df.corpus <- CapstoneDF$Reviews %>% VectorSource() %>% Corpus()
inspect(df.corpus[1:2])
df.corpus <- df.corpus %>% tm_map(removePunctuation)
df.corpus <- df.corpus %>% tm_map(removeWords, stopwords("english"))
inspect(df.corpus[1:2])
dtm <- TermDocumentMatrix(df.corpus) %>%
inspect(dtm)
wordmatrix <- as.matrix(dtm)
wordmatrix[1:5,1:5]
word_freqs = sort(rowSums(wordmatrix), decreasing=TRUE)
head(word_freqs)
library(readr)
library(dplyr)
library(tm)
library(wordcloud)
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
install.packages(c("tm","wordcloud","stringr","syuzhet"))
library(readr)
library(dplyr)
library(tm)
library(wordcloud)
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
test <- CapstoneDF$Reviews %>% VectorSource()
head(test)
test.corpus <- test %>% Corpus()
print(test.corpus)
inspect(test.corpus[[1]])
meta(test.corpus[[1]])
lapply(test.corpus[1:5],as.character)
test1 <- tm_map(test.corpus, removePunctuation)
inspect(test1[1])
test2 <- tm_map(test.corpus, removeWords, stopwords("english"))
inspect(test2[1])
inspect(test1[1])
df.corpus <- CapstoneDF$Reviews %>% VectorSource() %>% Corpus()
inspect(df.corpus[1:2])
df.corpus <- df.corpus %>% tm_map(removePunctuation)
df.corpus <- df.corpus %>% tm_map(removeWords, stopwords("english"))
inspect(df.corpus[1:2])
dtm <- TermDocumentMatrix(df.corpus) %>%
inspect(dtm)
dtm <- TermDocumentMatrix(df.corpus) %>%
inspect(dtm)
dtm <- TermDocumentMatrix(df.corpus)
inspect(dtm)
wordmatrix[1:5,1:5]
wordmatrix <- as.matrix(dtm)
wordmatrix[1:5,1:5]
word_freqs = sort(rowSums(wordmatrix), decreasing=TRUE)
head(word_freqs)
dm = data_frame(word=names(word_freqs), freq=word_freqs)
head(dm)
?wordcloud
wordcloud(df.corpus, min.freq=2,scale=c(4,0.5), max.word=1000, random.order=F)
word_freqs[1:5]
word_freqs <- word_freqs[-1]
word_freqs[1:5]
wordcloud(df.corpus, min.freq=2,scale=c(4,0.5), max.word=1000, random.order=F)
findAssocs(dtm, "good", .40)
findAssocs(dtm, "good", .20)
findAssocs(dtm, "good", .10)
findAssocs(dtm, "good", .15)
findAssocs(dtm, "good", .18)
findAssocs(dtm, "good", .20)
findAssocs(dtm, "service", .20)
findAssocs(dtm,"food",0.20)
findAssocs(dtm, "great", .20)
findAssocs(dtm, "drinks", .20)
findAssocs(dtm, "drinks", .25)
findAssocs(dtm, "dinner", .20)
findAssocs(dtm, "dinner", .25)
findAssocs(dtm, "dinner", .30)
findAssocs(dtm, "dinner", .33)
findAssocs(dtm, "service", .20)
findAssocs(dtm, "service", .18)
findAssocs(dtm, "time", .20)
findAssocs(dtm, "time", .25)
findAssocs(dtm, "atmosphere", .20)
findAssocs(dtm, "friendly", .20)
findAssocs(dtm, "friendly", .25)
findAssocs(dtm, "friendly", .26)
findAssocs(dtm, "friendly", .25)
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
suppressMessages(library(rvest))
YelpURL <- "https://www.yelp.ca/biz/reds-midtown-tavern-toronto-2"
YelpURL_data <-read_html(YelpURL)
print(YelpURL_data)
YelpReviews <- html_nodes(YelpURL_data, ".review-content p")
head(YelpReviews)
YelpReviews_char1 <- as.character(YelpReviews)
head(YelpReviews_char1, n=2)
YelpReviews_char2 <- html_text(YelpReviews)
head(YelpReviews_char2, n=2)
head(html_attrs(YelpReviews), n=3)
class(html_attrs(YelpReviews))
head(html_attr(YelpReviews, "lang"))
class(html_attr(YelpReviews, "lang"))
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
as.character(YelpRatings)[1]
head(html_attrs(YelpRatings), n=3)
YelpRatings_clean <- html_attr(YelpRatings, "title")
head(YelpRatings_clean)
rm(list=ls())
#Load required libraries
suppressMessages(library(rvest))
suppressMessages(library(dplyr))
library(tidyr)
suppressMessages(library(readr))
load("./Data/CapstoneRawData.RData")
str(YelpData)
str(OpenTableData)
str(TripAdData)
str(ZomatoData)
#Identify which reviews are not previous reviews and discard those that do
NoPrevRev <- grepl("has-previous-review",YelpData$PrevRev) == FALSE
YelpData$Ratings <- YelpData$Ratings[NoPrevRev]
YelpData$Dates <- YelpData$Dates[NoPrevRev]
#Create vector to describe the review category as Yelp
YelpVec <- rep("Yelp",length(YelpData$Reviews))
#Combine Yelp data vectors in DF
YelpDF <- data_frame(Reviews=YelpData$Reviews,Ratings=YelpData$Ratings,Dates=YelpData$Dates, Website=YelpVec)
# Create vector to describe category of OpenTable
OpenTableVec <- rep("OpenTable", length(OpenTableData$Reviews))
#Create OpenTable data frame
OpenTableDF <- data_frame(Reviews=OpenTableData$Reviews, Ratings=OpenTableData$Ratings, Dates=OpenTableData$Dates,Website=OpenTableVec)
#Remove the double values from the ratings, which take on NAs
ZomatoData$Ratings <- ZomatoData$Ratings[!is.na(ZomatoData$Ratings)]
#Remove duplicate reviews. These truncated duplicates have the regex
# "read more" within them.
FullRev <- !grepl("read more",ZomatoData$Reviews)
ZomatoData$Ratings <- ZomatoData$Ratings[FullRev]
ZomatoData$Reviews <- ZomatoData$Reviews[FullRev]
#Create vector describe website category
ZomatoVec <- rep("Zomato", length(ZomatoData$Reviews))
#Merge to data frame
ZomatoDF <- data_frame(Reviews=ZomatoData$Reviews,Ratings=ZomatoData$Ratings, Dates=ZomatoData$Dates, Website=ZomatoVec)
#Replace dates of the form "Reviewed ## days ago" with the proper dates
TripAdData$Dates2[grepl("ago|yesterday|today",TripAdData$Dates2)] <- TripAdData$Dates1
#Create vector describing website
TripAdVec <- rep("TripAdvisor",length(TripAdData$Reviews))
TripAdDF <- data_frame(Reviews=TripAdData$Reviews,Ratings=TripAdData$Ratings,Dates=TripAdData$Dates2,Website=TripAdVec)
#Merge all data frames
d1 <-suppressMessages(full_join(YelpDF,OpenTableDF))
d2 <- suppressMessages(full_join(d1,ZomatoDF))
CapstoneDF <- suppressMessages(full_join(d2,TripAdDF)) %>% group_by(Website)
str(CapstoneDF)
summary(CapstoneDF)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Yelp"),n=10)
#Remove newline characters and spaces
CapstoneDF$Dates <- gsub("\n *","",CapstoneDF$Dates)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Yelp"),n=10)
#Find data that doesn't fit Yelp pattern
UncleanDates <- CapstoneDF$Dates[!grepl("^[0-9].*[0-9]$",CapstoneDF$Dates)]
head(UncleanDates, n=10)
#Remove "Updated review"
CapstoneDF$Dates <- gsub("Updated review.*$","", CapstoneDF$Dates)
#Remove "Dined on "
CapstoneDF$Dates <- gsub("Dined on ","",CapstoneDF$Dates)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="OpenTable"),n=20)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"),n=20)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Zomato"),n=20)
#Remove "Reviewed "
CapstoneDF$Dates <- gsub("Reviewed ","",CapstoneDF$Dates)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"),n=20)
#Yelp date format is as follows
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Yelp"))
#grep for the Yelp dates
YelpDateRegex <- grep("^[0-9]+/.*[0-9]$",CapstoneDF$Dates)
#Given the dates, we will express them as date variables
CapstoneDF$Dates[YelpDateRegex] <- CapstoneDF$Dates[YelpDateRegex] %>% as.Date(format="%m/%d/%Y")
#Open Table date format:
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="OpenTable"))
#grep for Open Table dates and express as date variable
OpenTableDateRegex <- grep("^([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",CapstoneDF$Dates)
CapstoneDF$Dates[OpenTableDateRegex] <- CapstoneDF$Dates[OpenTableDateRegex] %>% as.Date(format="%B %d, %Y")
#Trip Advisor date format:
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"))
#grep for Trip Advisor dates and express as date variable
TripAdRegex <- grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",CapstoneDF$Dates)
CapstoneDF$Dates[TripAdRegex] <- CapstoneDF$Dates[TripAdRegex] %>% as.Date(format="%d %B %Y")
CapstoneDF$Dates[which(CapstoneDF$Website == "Zomato")] <- CapstoneDF$Dates[which(CapstoneDF$Website == "Zomato")] %>% as.Date()
class(CapstoneDF$Dates) <- "Date"
str(CapstoneDF$Dates)
#What do the Yelp ratings look like?
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="Yelp"))
#Get rid of "star rating"
CapstoneDF$Ratings <- gsub("star rating","",CapstoneDF$Ratings)
#Open Table ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="OpenTable"))
#TripAdvisor ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="TripAdvisor"))
#Get rid of "of 5 bubbles"
CapstoneDF$Ratings <- gsub("of [0-9] bubbles","",CapstoneDF$Ratings)
#Zomato ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="Zomato"))
#Get rid of "Rated "
CapstoneDF$Ratings <- gsub("Rated ","",CapstoneDF$Ratings)
#Impose numeric class
class(CapstoneDF$Ratings) <- "numeric"
str(CapstoneDF$Ratings)
#
CapstoneDF$Website <- factor(CapstoneDF$Website,order=FALSE,levels=c("Yelp","OpenTable","Zomato","TripAdvisor"))
str(CapstoneDF$Website)
levels(CapstoneDF$Website)
#Let's remove newline characters from reviews
CapstoneDF$Reviews <- gsub("\n","",CapstoneDF$Reviews)
#Clean up the Zomato reviews a bit by removing the "Rated" at the beginning
head(subset(CapstoneDF$Reviews,CapstoneDF$Website=="Zomato"), n=2)
CapstoneDF$Reviews <- gsub(" +Rated *","",CapstoneDF$Reviews)
head(subset(CapstoneDF$Reviews,CapstoneDF$Website=="Zomato"), n=2)
write_csv(CapstoneDF, "./Data/CapstoneCleanData.csv")
library(readr)
library(dplyr)
library(tm)
library(wordcloud)
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
CapstoneCorpus <- CapstoneDF$Reviews %>% VectorSource() %>% Corpus()
inspect(CapstoneCorpus[1:2])
CapstoneCorpus <- CapstoneCorpus %>% tm_map(removePunctuation)
inspect(CapstoneCorpus[1:2])
TermDocMatrix <- TermDocumentMatrix(CapstoneCorpus)
inspect(TermDocMatrix)
TermDocMatrix <- TermDocumentMatrix(CapstoneCorpus)
inspect(TermDocMatrix)
wordmatrix <- as.matrix(TermDocMatrix)
wordmatrix[1:5,1:5]
wordfreqs = sort(rowSums(wordmatrix), decreasing=TRUE)
head(wordfreqs)
CapstoneCorpus <- CapstoneCorpus %>% tm_map(removePunctuation)
CapstoneCorpus <- CapstoneCorpus %>% tm_map(removeWords, stopwords("english"))
inspect(CapstoneCorpus[1:2])
TermDocMatrix <- TermDocumentMatrix(CapstoneCorpus)
inspect(TermDocMatrix)
wordmatrix <- as.matrix(TermDocMatrix)
wordfreqs = sort(rowSums(wordmatrix), decreasing=TRUE)
head(wordfreqs)
WordFreqDF = data_frame(word=names(wordfreqs), freq=wordfreqs)
head(WordFreqDF)
WordFreqDF = data_frame(word=names(wordfreqs), freq=wordfreqs)
head(WordFreqDF)
wordcloud(CapstoneCorpus, min.freq=2,scale=c(4,0.5), max.word=1000, random.order=F)
suppressMessages(wordcloud(CapstoneCorpus, min.freq=2,scale=c(4,0.5), max.word=1000, random.order=F))
findAssocs(TermDocMatrix, "good", .20)
