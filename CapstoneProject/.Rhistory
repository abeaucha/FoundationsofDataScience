#grep for TripAdvisor dates and express as date variable
TripAdRegex <-
grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",
CapstoneDF$Dates)
CapstoneDF$Dates[TripAdRegex] <-
CapstoneDF$Dates[TripAdRegex] %>%
as.Date(format="%d %B %Y")
CapstoneDF$Dates[which(CapstoneDF$Website == "Zomato")] <-
CapstoneDF$Dates[which(CapstoneDF$Website == "Zomato")] %>%
as.Date()
class(CapstoneDF$Dates) <- "Date"
str(CapstoneDF$Dates, width=70, strict.width="cut")
#Yelp ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="Yelp"))
#Get rid of "star rating"
CapstoneDF$Ratings <- gsub("star rating","",CapstoneDF$Ratings)
#Open Table ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="OpenTable"))
#TripAdvisor ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="TripAdvisor"), n=4)
#Get rid of "of 5 bubbles"
CapstoneDF$Ratings <- gsub("of [0-9] bubbles","",CapstoneDF$Ratings)
#Zomato ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="Zomato"))
#Get rid of "Rated "
CapstoneDF$Ratings <- gsub("Rated ","",CapstoneDF$Ratings)
#Impose numeric class
class(CapstoneDF$Ratings) <- "numeric"
str(CapstoneDF$Ratings)
#Convert Websites to factor
CapstoneDF$Website <-
factor(CapstoneDF$Website,order=FALSE,
levels=c("Yelp","OpenTable","Zomato","TripAdvisor"))
str(CapstoneDF$Website)
levels(CapstoneDF$Website)
#Remove newline characters from reviews
CapstoneDF$Reviews <- gsub("\n","",CapstoneDF$Reviews)
#Clean up Zomato reviews by removing the "Rated" beginning
head(subset(CapstoneDF$Reviews,CapstoneDF$Website=="Zomato"), n=2) %>%
strtrim(65)
CapstoneDF$Reviews <- gsub(" +Rated *","",CapstoneDF$Reviews)
write_csv(CapstoneDF, "./Data/CapstoneCleanData.csv")
#Load libraries
library(readr)
library(dplyr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggplot2)
library(syuzhet)
#Read in clean data
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
#Summary of data frame
glimpse(CapstoneDF)
#Create variable describing annual quarters: Quarters
CapstoneDF <- CapstoneDF  %>% mutate(Quarters = quarters.Date(Dates))
#Separate Dates variable into Year, Month, Day variables
CapstoneDF <- CapstoneDF %>% separate(Dates, c("Year","Month","Day"))
#Create variable that describes Month and Year together: YearMonth
tempdf <- CapstoneDF %>% unite("YearMonth", Year, Month, sep="-")
CapstoneDF$YearMonth <- tempdf$YearMonth
#Create variable that describes Quarters and Year together: YearQuarters
tempdf <- CapstoneDF %>% unite("YearQuarters", Year, Quarters, sep="-")
CapstoneDF$YearQuarters <- tempdf$YearQuarters
#Convert Website and Quarters to factor class
CapstoneDF$Website <- factor(CapstoneDF$Website)
CapstoneDF$Quarters <- factor(CapstoneDF$Quarters)
t1 <- CapstoneDF %>% group_by(Year) %>% summarise(countYear=n())
CapstoneDF <- left_join(CapstoneDF,t1, by="Year")
t2 <- CapstoneDF %>% group_by(YearQuarters) %>% summarise(countQuarters=n())
CapstoneDF <- left_join(CapstoneDF,t2, by="YearQuarters")
t3 <- CapstoneDF %>% group_by(YearMonth) %>% summarise(countMonth=n())
CapstoneDF <- left_join(CapstoneDF,t3, by="YearMonth")
head(CapstoneDF[-1])
mean(CapstoneDF$Ratings)
CapstoneDF$RatingsAvg <-
rep(mean(CapstoneDF$Ratings), length(CapstoneDF$Ratings))
#Ratings aggregated by Year
ggplot(CapstoneDF, aes(x=Year, y=Ratings)) +
geom_line(aes(y=RatingsAvg, group=1), linetype="dashed",
colour="black", alpha=0.5) +
stat_summary(aes(size=countYear), fun.y=mean, geom="point", col="blue", alpha=0.8) +
#coord_cartesian(ylim=c(2.5,4.5)) +
scale_size_continuous(range=c(3,7)) +
coord_cartesian(ylim=c(3.0,4.5))
#Ratings aggregated by Year and Quarters
global_p2 <- ggplot(CapstoneDF, aes(x=YearQuarters, y=Ratings,col=Year)) +
geom_line(aes(y=RatingsAvg, group=1), linetype="dashed",
colour="black", alpha=0.5) +
stat_summary(aes(size=countQuarters), fun.y=mean, geom="point") +
#coord_cartesian(ylim=c(2.5,4.5)) +
coord_cartesian(ylim=c(3.0,4.5)) +
scale_size_continuous(range=c(3,9)) +
theme(axis.text.x =element_text(angle=90))
global_p2
global_p3 <- ggplot(CapstoneDF, aes(x=YearMonth, y=Ratings, col=Year)) +
geom_line(aes(y=RatingsAvg, group=1), linetype="dashed",
colour="black", alpha=0.5) +
stat_summary(aes(size=countMonth),fun.y=mean, geom="point", alpha=0.8) +
coord_cartesian(ylim=c(2.5,4.5)) +
scale_size_continuous(range=c(3,8)) +
theme(axis.text.x =element_text(angle=90))
global_p3
perc1 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==1))/dim(CapstoneDF)[1],2)
perc2 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==2))/dim(CapstoneDF)[1],2)
perc3 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==3))/dim(CapstoneDF)[1],2)
perc4 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==4))/dim(CapstoneDF)[1],2)
perc5 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==5))/dim(CapstoneDF)[1],2)
global_p4 <- ggplot(CapstoneDF, aes(x=ceiling(Ratings))) + geom_bar(aes(y=..count../sum(..count..)), col="blue", alpha=0.9)
global_p4
global_p7 <- ggplot(CapstoneDF, aes(ceiling(Ratings), y=..density.., col=Year)) +
geom_histogram(binwidth=1, alpha=0.9) +
facet_grid(.~Year)
global_p7
#Percentage time series analysis.
yearVec <- sort(unique(as.numeric(CapstoneDF$Year)))
#Build temporary data frame and round up Ratings
CapstoneDF_t <- CapstoneDF
CapstoneDF_t$Ratings <- ceiling(CapstoneDF_t$Ratings)
#Build data frames for rating counts by year
d1 <- CapstoneDF_t %>% group_by(Year,Ratings) %>% summarise(countRatings=n())
d2 <- CapstoneDF_t %>% group_by(Year) %>% summarise(countYear=n())
#Join data frames for ratings count and year counts
percentData <- left_join(d1,d2, by="Year")
percentData$Ratings <- ceiling(percentData$Ratings)
#Create observations for instances when no ratings of that number of stars have been observed
vec2 <- NULL
for(i in 1:length(yearVec)){
vec <- percentData$Ratings %>% subset(percentData$Year == yearVec[i])
if(!(1 %in% vec)){
yearCount <- subset(percentData$countYear, percentData$Year==yearVec[i])[1]
vec2 <- data.frame(Year=as.character(yearVec[i]), Ratings=as.numeric(1), countRatings=as.integer(0), countYear=as.integer(yearCount))
percentData <- (bind_rows(vec2, as.data.frame(percentData)))
}
}
#Calculate ratings percentages
percentData <- percentData %>% arrange(Ratings) %>%  mutate(percentRatings = countRatings/countYear)
#Select columns
percentData <- percentData %>% select(Year,Ratings,percentRatings, countYear) %>% arrange(Year,Ratings)
#Treat Ratings as ordinal variables
percentData$Ratings <- factor(percentData$Ratings)
ggplot(percentData, aes(x=Year, y=percentRatings, group=Ratings)) +
geom_smooth(data=subset(percentData, percentData$Ratings==1), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==2), method="lm", se=T, formula=y~poly(x,1, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==3), method="lm", se=T, formula=y~poly(x,1, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==4), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==5), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_point(aes(col=Ratings,  size=countYear), alpha=0.9) +
scale_size_continuous(range=c(3,7))
?wordcloud
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=100, max.word=200, random.order=F)
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=100, max.word=200, random.order=F, scale=c(4,0.5))
CapstoneDir = "/Users/Antoine/Documents/Work/DataScience/Springboard/FoundationsofDataScience/CapstoneProject"
setwd(CapstoneDir)
rm(list=ls())
#Set default options for R code chuncks in Markdown.
library(knitr)
opts_chunk$set(tidy=FALSE, message=FALSE, size="small", highlight = TRUE, background=c(0,0,0))
# Function to break long strings up for display
# Source: http://stackoverflow.com/questions/24020617/
#textwrapping-long-string-in-knitr-output-rstudio
str_break = function(x, width = 60L) {
n = nchar(x)
if (n <= width) return(x)
n1 = seq(1L, n, by = width)
n2 = seq(width, n, by = width)
if (n %% width != 0) n2 = c(n2, n)
substring(x, n1, n2)
}
library(rvest)
YelpURL <- "https://www.yelp.ca/biz/reds-midtown-tavern-toronto-2"
YelpURL_data <-read_html(YelpURL)
YelpReviews <- html_nodes(YelpURL_data, ".review-content p")
head(YelpReviews)
YelpReviews_char1 <- as.character(YelpReviews)
strtrim(head(YelpReviews_char1, n=2),65)
class(YelpReviews_char1)
YelpReviews_char2 <- html_text(YelpReviews)
strtrim(head(YelpReviews_char2, n=2),65)
head(html_attrs(YelpReviews), n=2)
class(html_attrs(YelpReviews))
head(html_attr(YelpReviews, "lang"))
class(html_attr(YelpReviews, "lang"))
YelpRatings <- html_nodes(YelpURL_data, ".rating-large")
as.character(YelpRatings)[1] %>% str_break()
head(html_attrs(YelpRatings), n=2)
YelpRatings_clean <- html_attr(YelpRatings, "title")
head(YelpRatings_clean)
rm(list=ls())
#Load required libraries
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
load("./Data/CapstoneRawData.RData")
#Examine Yelp data
str(YelpData, width=70, strict.width = "cut")
#Examine OpenTable data
str(OpenTableData, width=70, strict.width = "cut")
#Examine TripAdvisor data
str(TripAdData, width=70, strict.width = "cut")
#Examine Zomato data
str(ZomatoData, width=70, strict.width = "cut")
#Which reviews are not previous reviews?
NoPrevRev <- !grepl("has-previous-review",YelpData$PrevRev)
YelpData$Ratings <- YelpData$Ratings[NoPrevRev]
YelpData$Dates <- YelpData$Dates[NoPrevRev]
#Vector, Yelp identifier
YelpVec <- rep("Yelp",length(YelpData$Reviews))
#Combine to data frame
YelpDF <- data_frame(Reviews=YelpData$Reviews,
Ratings=YelpData$Ratings,
Dates=YelpData$Dates,
Website=YelpVec)
#Vector, OpenTable identifier
OpenTableVec <- rep("OpenTable", length(OpenTableData$Reviews))
#Merge to data frame
OpenTableDF <- data_frame(Reviews=OpenTableData$Reviews,
Ratings=OpenTableData$Ratings,
Dates=OpenTableData$Dates,
Website=OpenTableVec)
#Remove NAs from ratings
ZomatoData$Ratings <- ZomatoData$Ratings[!is.na(ZomatoData$Ratings)]
#Remove duplicate reviews. These truncated duplicates can be
# identified with the regex "read more"
FullRev <- !grepl("read more",ZomatoData$Reviews)
ZomatoData$Ratings <- ZomatoData$Ratings[FullRev]
ZomatoData$Reviews <- ZomatoData$Reviews[FullRev]
#Vector, Zomato identifier
ZomatoVec <- rep("Zomato", length(ZomatoData$Reviews))
#Merge to data frame
ZomatoDF <- data_frame(Reviews=ZomatoData$Reviews,
Ratings=ZomatoData$Ratings,
Dates=ZomatoData$Dates,
Website=ZomatoVec)
#Replace dates of the form "Reviewed ## days ago" with the proper dates
TripAdData$Dates2[grepl("ago|yesterday|today",TripAdData$Dates2)] <-
TripAdData$Dates1
##Vector, TripAdvisor identifier
TripAdVec <- rep("TripAdvisor",length(TripAdData$Reviews))
#Merge to data frame
TripAdDF <- data_frame(Reviews=TripAdData$Reviews,
Ratings=TripAdData$Ratings,
Dates=TripAdData$Dates2,
Website=TripAdVec)
#Merge all data frames
d1 <- full_join(YelpDF,OpenTableDF)
d2 <- full_join(d1,ZomatoDF)
CapstoneDF <- full_join(d2,TripAdDF) %>% group_by(Website)
str(CapstoneDF, width=70, strict.width = "cut", give.attr = FALSE)
summary(CapstoneDF)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Yelp"),n=4)
#Remove newline characters and spaces
CapstoneDF$Dates <- gsub("\n *","",CapstoneDF$Dates)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Yelp"),n=10)
#Find data that doesn't fit Yelp pattern
UncleanDates <- CapstoneDF$Dates[!grepl("^[0-9].*[0-9]$",CapstoneDF$Dates)]
head(UncleanDates, n=6)
#Remove "Updated review"
CapstoneDF$Dates <- gsub("Updated review.*$","", CapstoneDF$Dates)
#Remove "Dined on "
CapstoneDF$Dates <- gsub("Dined on ","",CapstoneDF$Dates)
#OpenTable
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="OpenTable"),n=9)
#TripAdvisor
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"),n=10)
#Zomato
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Zomato"),n=6)
#Remove "Reviewed " from TripAdvisor data
CapstoneDF$Dates <- gsub("Reviewed ","",CapstoneDF$Dates)
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"))
#Yelp date format
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="Yelp"))
#grep for the Yelp dates
YelpDateRegex <- grep("^[0-9]+/.*[0-9]$",CapstoneDF$Dates)
#Express dates as date variables
CapstoneDF$Dates[YelpDateRegex] <-
CapstoneDF$Dates[YelpDateRegex] %>%
as.Date(format="%m/%d/%Y")
#Open Table date format:
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="OpenTable"))
#grep for OpenTable dates and express as date
OpenTableDateRegex <-
grep("^([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",
CapstoneDF$Dates)
CapstoneDF$Dates[OpenTableDateRegex] <-
CapstoneDF$Dates[OpenTableDateRegex] %>%
as.Date(format="%B %d, %Y")
#TripAdvisor date format:
head(subset(CapstoneDF$Dates, CapstoneDF$Website=="TripAdvisor"))
#grep for TripAdvisor dates and express as date variable
TripAdRegex <-
grep("^[0-9]+ ([Jj]|[Ff]|[Mm]|[Aa]|[Jj]|[Ss]|[Oo]|[Nn]|[Dd]).+[0-9]+$",
CapstoneDF$Dates)
CapstoneDF$Dates[TripAdRegex] <-
CapstoneDF$Dates[TripAdRegex] %>%
as.Date(format="%d %B %Y")
CapstoneDF$Dates[which(CapstoneDF$Website == "Zomato")] <-
CapstoneDF$Dates[which(CapstoneDF$Website == "Zomato")] %>%
as.Date()
class(CapstoneDF$Dates) <- "Date"
str(CapstoneDF$Dates, width=70, strict.width="cut")
#Yelp ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="Yelp"))
#Get rid of "star rating"
CapstoneDF$Ratings <- gsub("star rating","",CapstoneDF$Ratings)
#Open Table ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="OpenTable"))
#TripAdvisor ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="TripAdvisor"), n=4)
#Get rid of "of 5 bubbles"
CapstoneDF$Ratings <- gsub("of [0-9] bubbles","",CapstoneDF$Ratings)
#Zomato ratings
head(subset(CapstoneDF$Ratings, CapstoneDF$Website=="Zomato"))
#Get rid of "Rated "
CapstoneDF$Ratings <- gsub("Rated ","",CapstoneDF$Ratings)
#Impose numeric class
class(CapstoneDF$Ratings) <- "numeric"
str(CapstoneDF$Ratings)
#Convert Websites to factor
CapstoneDF$Website <-
factor(CapstoneDF$Website,order=FALSE,
levels=c("Yelp","OpenTable","Zomato","TripAdvisor"))
str(CapstoneDF$Website)
levels(CapstoneDF$Website)
#Remove newline characters from reviews
CapstoneDF$Reviews <- gsub("\n","",CapstoneDF$Reviews)
#Clean up Zomato reviews by removing the "Rated" beginning
head(subset(CapstoneDF$Reviews,CapstoneDF$Website=="Zomato"), n=2) %>%
strtrim(65)
CapstoneDF$Reviews <- gsub(" +Rated *","",CapstoneDF$Reviews)
write_csv(CapstoneDF, "./Data/CapstoneCleanData.csv")
#Load libraries
library(readr)
library(dplyr)
library(tidyr)
library(tm)
library(wordcloud)
library(ggplot2)
library(syuzhet)
#Read in clean data
CapstoneDF <- read_csv("./Data/CapstoneCleanData.csv")
#Summary of data frame
glimpse(CapstoneDF)
#Create variable describing annual quarters: Quarters
CapstoneDF <- CapstoneDF  %>% mutate(Quarters = quarters.Date(Dates))
#Separate Dates variable into Year, Month, Day variables
CapstoneDF <- CapstoneDF %>% separate(Dates, c("Year","Month","Day"))
#Create variable that describes Month and Year together: YearMonth
tempdf <- CapstoneDF %>% unite("YearMonth", Year, Month, sep="-")
CapstoneDF$YearMonth <- tempdf$YearMonth
#Create variable that describes Quarters and Year together: YearQuarters
tempdf <- CapstoneDF %>% unite("YearQuarters", Year, Quarters, sep="-")
CapstoneDF$YearQuarters <- tempdf$YearQuarters
#Convert Website and Quarters to factor class
CapstoneDF$Website <- factor(CapstoneDF$Website)
CapstoneDF$Quarters <- factor(CapstoneDF$Quarters)
t1 <- CapstoneDF %>% group_by(Year) %>% summarise(countYear=n())
CapstoneDF <- left_join(CapstoneDF,t1, by="Year")
t2 <- CapstoneDF %>% group_by(YearQuarters) %>% summarise(countQuarters=n())
CapstoneDF <- left_join(CapstoneDF,t2, by="YearQuarters")
t3 <- CapstoneDF %>% group_by(YearMonth) %>% summarise(countMonth=n())
CapstoneDF <- left_join(CapstoneDF,t3, by="YearMonth")
head(CapstoneDF[-1])
mean(CapstoneDF$Ratings)
CapstoneDF$RatingsAvg <-
rep(mean(CapstoneDF$Ratings), length(CapstoneDF$Ratings))
#Ratings aggregated by Year
ggplot(CapstoneDF, aes(x=Year, y=Ratings)) +
geom_line(aes(y=RatingsAvg, group=1), linetype="dashed",
colour="black", alpha=0.5) +
stat_summary(aes(size=countYear), fun.y=mean, geom="point", col="blue", alpha=0.8) +
#coord_cartesian(ylim=c(2.5,4.5)) +
scale_size_continuous(range=c(3,7)) +
coord_cartesian(ylim=c(3.0,4.5))
#Ratings aggregated by Year and Quarters
global_p2 <- ggplot(CapstoneDF, aes(x=YearQuarters, y=Ratings,col=Year)) +
geom_line(aes(y=RatingsAvg, group=1), linetype="dashed",
colour="black", alpha=0.5) +
stat_summary(aes(size=countQuarters), fun.y=mean, geom="point") +
#coord_cartesian(ylim=c(2.5,4.5)) +
coord_cartesian(ylim=c(3.0,4.5)) +
scale_size_continuous(range=c(3,9)) +
theme(axis.text.x =element_text(angle=90))
global_p2
global_p3 <- ggplot(CapstoneDF, aes(x=YearMonth, y=Ratings, col=Year)) +
geom_line(aes(y=RatingsAvg, group=1), linetype="dashed",
colour="black", alpha=0.5) +
stat_summary(aes(size=countMonth),fun.y=mean, geom="point", alpha=0.8) +
coord_cartesian(ylim=c(2.5,4.5)) +
scale_size_continuous(range=c(3,8)) +
theme(axis.text.x =element_text(angle=90))
global_p3
perc1 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==1))/dim(CapstoneDF)[1],2)
perc2 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==2))/dim(CapstoneDF)[1],2)
perc3 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==3))/dim(CapstoneDF)[1],2)
perc4 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==4))/dim(CapstoneDF)[1],2)
perc5 <- round(length(subset(CapstoneDF$Ratings, ceiling(CapstoneDF$Ratings)==5))/dim(CapstoneDF)[1],2)
global_p4 <- ggplot(CapstoneDF, aes(x=ceiling(Ratings))) + geom_bar(aes(y=..count../sum(..count..)), col="blue", alpha=0.9)
global_p4
global_p7 <- ggplot(CapstoneDF, aes(ceiling(Ratings), y=..density.., col=Year)) +
geom_histogram(binwidth=1, alpha=0.9) +
facet_grid(.~Year)
global_p7
#Percentage time series analysis.
yearVec <- sort(unique(as.numeric(CapstoneDF$Year)))
#Build temporary data frame and round up Ratings
CapstoneDF_t <- CapstoneDF
CapstoneDF_t$Ratings <- ceiling(CapstoneDF_t$Ratings)
#Build data frames for rating counts by year
d1 <- CapstoneDF_t %>% group_by(Year,Ratings) %>% summarise(countRatings=n())
d2 <- CapstoneDF_t %>% group_by(Year) %>% summarise(countYear=n())
#Join data frames for ratings count and year counts
percentData <- left_join(d1,d2, by="Year")
percentData$Ratings <- ceiling(percentData$Ratings)
#Create observations for instances when no ratings of that number of stars have been observed
vec2 <- NULL
for(i in 1:length(yearVec)){
vec <- percentData$Ratings %>% subset(percentData$Year == yearVec[i])
if(!(1 %in% vec)){
yearCount <- subset(percentData$countYear, percentData$Year==yearVec[i])[1]
vec2 <- data.frame(Year=as.character(yearVec[i]), Ratings=as.numeric(1), countRatings=as.integer(0), countYear=as.integer(yearCount))
percentData <- (bind_rows(vec2, as.data.frame(percentData)))
}
}
#Calculate ratings percentages
percentData <- percentData %>% arrange(Ratings) %>%  mutate(percentRatings = countRatings/countYear)
#Select columns
percentData <- percentData %>% select(Year,Ratings,percentRatings, countYear) %>% arrange(Year,Ratings)
#Treat Ratings as ordinal variables
percentData$Ratings <- factor(percentData$Ratings)
ggplot(percentData, aes(x=Year, y=percentRatings, group=Ratings)) +
geom_smooth(data=subset(percentData, percentData$Ratings==1), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==2), method="lm", se=T, formula=y~poly(x,1, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==3), method="lm", se=T, formula=y~poly(x,1, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==4), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_smooth(data=subset(percentData, percentData$Ratings==5), method="lm", se=T, formula=y~poly(x,2, raw=TRUE), linetype="dashed", size=0.5, alpha=0.15, col="black") +
geom_point(aes(col=Ratings,  size=countYear), alpha=0.9) +
scale_size_continuous(range=c(3,7))
# Function: WordCloudAnalysis
#
# This function takes a dataset containing customer reviews and prepares the data for text analysis using the tm package.
# analysis
# Input: Data frame containing Review variable that has customer reviews
# Output: List containing text analytics properties of reviews such as Corpus, Term Document Matrix, and word freqneucies.
#
WordCloudAnalysis <- function(dataset, use.sentences=TRUE){
#Remove "The" or "the"  from reviews, since the tm_map() function below doesn't do it.
dataset$Reviews <- gsub("[Tt]he", "", dataset$Reviews)
#Options to split review text into individual sentences. This improves the use of the findAssocs() function later on.
if(use.sentences==TRUE){
dataCorpus <- get_sentences(dataset$Reviews) %>% VectorSource %>% Corpus()
}
else {
#Create corpus from the full text data
dataCorpus <- dataset$Reviews %>% VectorSource() %>% Corpus()
}
#Remove punctuation and english stopwords from text data
dataCorpus <- dataCorpus %>%
tm_map(removePunctuation) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower))
#Create term document matrix and convert to matrix class.
TDM <- TermDocumentMatrix(dataCorpus)
TDM_m <- TDM %>% as.matrix()
#Compute word frequencies from TDM.
wFreqs = sort(rowSums(TDM_m), decreasing=TRUE)
return(list("Corpus" = dataCorpus, "TDM"=TDM, "wordFreq"=wFreqs))
}
#Word analysis
Capstone_wA <- WordCloudAnalysis(CapstoneDF)
#Most common words
head(Capstone_wA$wordFreq, n=20)
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=100, max.word=200, random.order=F, scale=c(4,0.5))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(2,0.5), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(2,0.1), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(2,0), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(5,0), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(5,5), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(5,2), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(5,0.2), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(5,0.2), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(5,0.5), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(4,0.5), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(3,0.5), colors=brewer.pal(8, "Dark2"))
#Generate wordcloud
wordcloud(Capstone_wA$Corpus,min.freq=75, max.word=200, random.order=F, scale=c(2,0.5), colors=brewer.pal(8, "Dark2"))
#Now this is the part where Saurabh suggest I do my hypotheses.
# Obvious one to start with is food. Associations aren't really relevant.
# E.g. the strongest one is "came".
findAssocs(Capstone_wA$TDM, "reds", 0.20)
findAssocs(Capstone_wA$TDM, "food", .18)
findAssocs(Capstone_wA$TDM, "good", .15)
findAssocs(Capstone_wA$TDM, "great", .10)
findAssocs(Capstone_wA$TDM, "service", 0.15)
findAssocs(Capstone_wA$TDM, "place", 0.20)
findAssocs(Capstone_wA$TDM, "place", 0.15)
findAssocs(Capstone_wA$TDM, "place", 0.10)
